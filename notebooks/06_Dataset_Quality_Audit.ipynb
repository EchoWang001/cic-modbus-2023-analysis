{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7322a75f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "排查1：数据集目录结构分析\n",
            "============================================================\n",
            "\n",
            "总PCAP文件数: 170\n",
            "总CSV文件数: 34\n",
            "\n",
            "============================================================\n",
            "PCAP文件按目录分组:\n",
            "============================================================\n",
            "                                                                       count  total_size_mb\n",
            "directory                                                                                  \n",
            "attack\\compromised-ied\\central-agent\\central-agent-network-captures        5     459.408956\n",
            "attack\\compromised-ied\\ied1a\\ied1a-network-captures                        6     516.835071\n",
            "attack\\compromised-ied\\ied1b\\ied1b-network-captures                        6     495.868903\n",
            "attack\\compromised-ied\\ied4c\\ied4c-network-captures                        6     517.878103\n",
            "attack\\compromised-ied\\trust-scada-hmi\\trust-scada-network-captures       20    1902.950409\n",
            "attack\\compromised-scada\\central-agent\\central-agent-network-captures      2     123.989984\n",
            "attack\\compromised-scada\\ied1a\\ied1a-network-captures                      6     520.922754\n",
            "attack\\compromised-scada\\ied1b\\ied1b-network-captures                      8     680.314793\n",
            "attack\\compromised-scada\\ied4c\\ied4c-network-captures                      6     510.603864\n",
            "attack\\compromised-scada\\scada-hmi\\scada-hmi-network-capture              17    1587.624561\n",
            "attack\\compromised-scada\\substation-wide-capture                          18    1615.985397\n",
            "attack\\external\\central-agent                                              1       2.612788\n",
            "attack\\external\\external-attacker\\external-attacker-network-capture        1      43.852318\n",
            "attack\\external\\ied1a                                                      1      77.093761\n",
            "attack\\external\\ied1b                                                      1      29.717238\n",
            "attack\\external\\ied4c                                                      1      33.229764\n",
            "attack\\external\\network-wide                                               2     139.990694\n",
            "attack\\external\\scada-hmi                                                  1      93.552165\n",
            "benign\\central-agent\\central-agent-network-capture                         1      84.418697\n",
            "benign\\ied1a\\ied1a-network-capture                                         8     691.520921\n",
            "benign\\ied1b\\ied1b-network-capture                                         7     575.029233\n",
            "benign\\ied4c\\ied4c-network-capture                                         8     687.887939\n",
            "benign\\network-wide-pcap-capture\\network-wide                             19    1761.089411\n",
            "benign\\scada-hmi\\scada-hmi-network-capture                                19    1772.640379\n",
            "\n",
            "============================================================\n",
            "CSV文件按目录分组:\n",
            "============================================================\n",
            "directory\n",
            "attack\\compromised-ied\\attack logs\\03-23-2023                 1\n",
            "attack\\compromised-ied\\attack logs\\03-24-2023                 1\n",
            "attack\\compromised-ied\\attack logs\\03-25-2023                 1\n",
            "attack\\compromised-ied\\attack logs\\03-26-2023                 1\n",
            "attack\\compromised-ied\\attack logs\\03-27-2023                 1\n",
            "attack\\compromised-ied\\attack logs\\03-28-2023                 1\n",
            "attack\\compromised-ied\\attack logs\\03-29-2023                 1\n",
            "attack\\compromised-scada\\attack logs\\03-12-2023               3\n",
            "attack\\compromised-scada\\attack logs\\03-13-2023               2\n",
            "attack\\compromised-scada\\attack logs\\03-14-2023               3\n",
            "attack\\compromised-scada\\attack logs\\03-15-2023               3\n",
            "attack\\compromised-scada\\attack logs\\03-16-2023               3\n",
            "attack\\compromised-scada\\attack logs\\03-17-2023               2\n",
            "attack\\compromised-scada\\attack logs\\03-18-2023               1\n",
            "attack\\compromised-scada\\attack logs\\03-19-2023               1\n",
            "attack\\compromised-scada\\attack logs\\03-20-2023               1\n",
            "attack\\compromised-scada\\attack logs\\03-21-2023               1\n",
            "attack\\compromised-scada\\attack logs\\03-22-2023               1\n",
            "attack\\external\\external-attacker\\attacker logs\\01-01-2023    1\n",
            "attack\\external\\external-attacker\\attacker logs\\01-02-2023    1\n",
            "attack\\external\\external-attacker\\attacker logs\\01-17-2023    1\n",
            "attack\\external\\external-attacker\\attacker logs\\02-01-2023    1\n",
            "attack\\external\\external-attacker\\attacker logs\\12-29-2022    1\n",
            "attack\\external\\external-attacker\\attacker logs\\12-30-2022    1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "sys.path.append(r'C:\\Users\\Echo\\Desktop\\modbus-detection\\src')\n",
        "import config\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Investigation 1: Dataset Directory Structure Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "dataset_root = config.DATASET_ROOT\n",
        "\n",
        "#  Recursively scan all PCAP and CSV files\n",
        "all_files = {\n",
        "    'pcap': [],\n",
        "    'csv': []\n",
        "}\n",
        "\n",
        "for root, dirs, files in os.walk(dataset_root):\n",
        "    for file in files:\n",
        "        full_path = os.path.join(root, file)\n",
        "        rel_path = os.path.relpath(full_path, dataset_root)\n",
        "        \n",
        "        if file.endswith('.pcap'):\n",
        "            all_files['pcap'].append({\n",
        "                'file': file,\n",
        "                'path': rel_path,\n",
        "                'directory': os.path.dirname(rel_path),\n",
        "                'size_mb': os.path.getsize(full_path) / (1024**2)\n",
        "            })\n",
        "        elif file.endswith('.csv'):\n",
        "            all_files['csv'].append({\n",
        "                'file': file,\n",
        "                'path': rel_path,\n",
        "                'directory': os.path.dirname(rel_path)\n",
        "            })\n",
        "\n",
        "print(f\"\\nTotal PCAP files: {len(all_files['pcap'])}\")\n",
        "print(f\"Total CSV files: {len(all_files['csv'])}\")\n",
        "\n",
        "#  Create DataFrame for analysis\n",
        "df_pcap = pd.DataFrame(all_files['pcap'])\n",
        "df_csv = pd.DataFrame(all_files['csv'])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PCAP files grouped by directory:\")\n",
        "print(\"=\" * 60)\n",
        "pcap_by_dir = df_pcap.groupby('directory').agg({\n",
        "    'file': 'count',\n",
        "    'size_mb': 'sum'\n",
        "}).rename(columns={'file': 'count', 'size_mb': 'total_size_mb'})\n",
        "print(pcap_by_dir.to_string())\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"CSV files grouped by directory:\")\n",
        "print(\"=\" * 60)\n",
        "csv_by_dir = df_csv.groupby('directory')['file'].count()\n",
        "print(csv_by_dir.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "97c60eb3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "排查2：检查文件命名异常\n",
            "============================================================\n",
            "\n",
            "External目录下的PCAP文件 (8 个):\n",
            "------------------------------------------------------------\n",
            "✓ veth460b141-0.pcap\n",
            "   路径: attack\\external\\central-agent\\veth460b141-0.pcap\n",
            "   大小: 2.6 MB\n",
            "\n",
            "✓ veth665f3cf-0.pcap\n",
            "   路径: attack\\external\\external-attacker\\external-attacker-network-capture\\veth665f3cf-0.pcap\n",
            "   大小: 43.9 MB\n",
            "\n",
            "✓ veth4edc015-0.pcap\n",
            "   路径: attack\\external\\ied1a\\veth4edc015-0.pcap\n",
            "   大小: 77.1 MB\n",
            "\n",
            "✓ vethd9e14c0-0.pcap\n",
            "   路径: attack\\external\\ied1b\\vethd9e14c0-0.pcap\n",
            "   大小: 29.7 MB\n",
            "\n",
            "✓ veth8bc3408-0.pcap\n",
            "   路径: attack\\external\\ied4c\\veth8bc3408-0.pcap\n",
            "   大小: 33.2 MB\n",
            "\n",
            "⚠️ 可疑 network-wide-normal-0.pcap\n",
            "   路径: attack\\external\\network-wide\\network-wide-normal-0.pcap\n",
            "   大小: 95.4 MB\n",
            "\n",
            "⚠️ 可疑 network-wide-normal-1.pcap\n",
            "   路径: attack\\external\\network-wide\\network-wide-normal-1.pcap\n",
            "   大小: 44.6 MB\n",
            "\n",
            "✓ veth5bbeaa2-0.pcap\n",
            "   路径: attack\\external\\scada-hmi\\veth5bbeaa2-0.pcap\n",
            "   大小: 93.6 MB\n",
            "\n",
            "\n",
            "============================================================\n",
            "⚠️  发现 2 个可疑文件:\n",
            "============================================================\n",
            "文件: network-wide-normal-0.pcap\n",
            "路径: attack\\external\\network-wide\\network-wide-normal-0.pcap\n",
            "问题: 文件名包含\"normal\"但在External目录\n",
            "\n",
            "文件: network-wide-normal-1.pcap\n",
            "路径: attack\\external\\network-wide\\network-wide-normal-1.pcap\n",
            "问题: 文件名包含\"normal\"但在External目录\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Investigation 2: Check File Naming Anomalies\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "#  Check PCAP files in External directory\n",
        "external_pcaps = df_pcap[df_pcap['directory'].str.contains('external', case=False, na=False)]\n",
        "\n",
        "print(f\"\\nPCAP files in External directory ({len(external_pcaps)} files):\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "suspicious_files = []\n",
        "\n",
        "for idx, row in external_pcaps.iterrows():\n",
        "    filename = row['file']\n",
        "    path = row['path']\n",
        "    \n",
        "    #  Check if filename contains \"normal\" keyword (should be in benign directory, not external)\n",
        "    is_suspicious = 'normal' in filename.lower()\n",
        "    \n",
        "    marker = \"⚠️ Suspicious\" if is_suspicious else \"✓\"\n",
        "    print(f\"{marker} {filename}\")\n",
        "    print(f\"   Path: {path}\")\n",
        "    print(f\"   Size: {row['size_mb']:.1f} MB\")\n",
        "    \n",
        "    if is_suspicious:\n",
        "        suspicious_files.append({\n",
        "            'file': filename,\n",
        "            'path': path,\n",
        "            'reason': 'Filename contains \"normal\" but in External directory'\n",
        "        })\n",
        "    print()\n",
        "\n",
        "if suspicious_files:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"⚠️  Found {len(suspicious_files)} suspicious files:\")\n",
        "    print(\"=\" * 60)\n",
        "    for f in suspicious_files:\n",
        "        print(f\"File: {f['file']}\")\n",
        "        print(f\"Path: {f['path']}\")\n",
        "        print(f\"Issue: {f['reason']}\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"\\n✓ No file organization anomalies found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "50cad3d6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "排查3：文件命名一致性分析\n",
            "============================================================\n",
            "\n",
            "文件命名模式统计:\n",
            "------------------------------------------------------------\n",
            "\n",
            "veth开头: 131 个文件\n",
            "  - vethffb308b-0.pcap (attack\\compromised-ied\\central-agent\\central-agent-network-captures)\n",
            "  - vethffb308b-1.pcap (attack\\compromised-ied\\central-agent\\central-agent-network-captures)\n",
            "  - vethffb308b-2.pcap (attack\\compromised-ied\\central-agent\\central-agent-network-captures)\n",
            "  ... 还有 128 个\n",
            "\n",
            "substation开头: 18 个文件\n",
            "  - substation-0.pcap (attack\\compromised-scada\\substation-wide-capture)\n",
            "  - substation-1.pcap (attack\\compromised-scada\\substation-wide-capture)\n",
            "  - substation-10.pcap (attack\\compromised-scada\\substation-wide-capture)\n",
            "  ... 还有 15 个\n",
            "\n",
            "network-wide开头: 21 个文件\n",
            "  - network-wide-normal-0.pcap (attack\\external\\network-wide)\n",
            "  - network-wide-normal-1.pcap (attack\\external\\network-wide)\n",
            "  - network-wide-normal-14.pcap (benign\\network-wide-pcap-capture\\network-wide)\n",
            "  ... 还有 18 个\n",
            "\n",
            "============================================================\n",
            "命名一致性评估:\n",
            "============================================================\n",
            "\n",
            "观察结果:\n",
            "1. veth开头 (131 个): Docker虚拟网卡命名，NIC捕获\n",
            "2. substation开头 (18 个): 全网捕获\n",
            "3. network-wide开头 (21 个): 全网捕获\n",
            "4. 其他 (0 个): 需要检查\n",
            "\n",
            "✓ 命名混乱程度: 低\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Investigation 3: File Naming Consistency Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "#  Analyze file naming patterns\n",
        "import re\n",
        "\n",
        "naming_patterns = {\n",
        "    'veth prefix': [],\n",
        "    'substation prefix': [],\n",
        "    'network-wide prefix': [],\n",
        "    'ied prefix': [],\n",
        "    'other': []\n",
        "}\n",
        "\n",
        "for idx, row in df_pcap.iterrows():\n",
        "    filename = row['file']\n",
        "    \n",
        "    if filename.startswith('veth'):\n",
        "        naming_patterns['veth prefix'].append(row)\n",
        "    elif filename.startswith('substation'):\n",
        "        naming_patterns['substation prefix'].append(row)\n",
        "    elif filename.startswith('network-wide'):\n",
        "        naming_patterns['network-wide prefix'].append(row)\n",
        "    elif filename.startswith('ied'):\n",
        "        naming_patterns['ied prefix'].append(row)\n",
        "    else:\n",
        "        naming_patterns['other'].append(row)\n",
        "\n",
        "print(\"\\nFile naming pattern statistics:\")\n",
        "print(\"-\" * 60)\n",
        "for pattern, files in naming_patterns.items():\n",
        "    if files:\n",
        "        print(f\"\\n{pattern}: {len(files)} files\")\n",
        "        #  Show examples\n",
        "        for f in files[:3]:\n",
        "            print(f\"  - {f['file']} ({f['directory']})\")\n",
        "        if len(files) > 3:\n",
        "            print(f\"  ... and {len(files)-3} more\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Naming consistency assessment:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\"\"\n",
        "Observations:\n",
        "1. veth prefix ({len(naming_patterns['veth prefix'])} files): Docker virtual NIC naming, NIC capture\n",
        "2. substation prefix ({len(naming_patterns['substation prefix'])} files): Network-wide capture\n",
        "3. network-wide prefix ({len(naming_patterns['network-wide prefix'])} files): Network-wide capture\n",
        "4. other ({len(naming_patterns['other'])} files): Need to check\n",
        "\n",
        "✓ Naming confusion level: {'High' if len(naming_patterns['other']) > 5 else 'Medium' if len(naming_patterns['other']) > 0 else 'Low'}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "539fe4ca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "排查4：CSV标签质量对比分析\n",
            "============================================================\n",
            "\n",
            "CSV标签列结构对比:\n",
            "------------------------------------------------------------\n",
            "      场景  列数                                         列名  有Timestamp  有TargetIP  有TransactionID  有Attack     行数\n",
            "External   2                          Timestamp, Attack        True      False           False     True      1\n",
            "     IED   4 Timestamp, TargetIP, Attack, TransactionID        True       True            True     True     66\n",
            "   SCADA   4 Timestamp, TargetIP, Attack, TransactionID        True       True            True     True 107770\n",
            "\n",
            "============================================================\n",
            "标签质量评估:\n",
            "============================================================\n",
            "\n",
            "External:\n",
            "  ⚠️  缺少列: TargetIP, TransactionID\n",
            "  前3行示例:\n",
            "              Timestamp              Attack\n",
            "2023-01-01 21:00:44.389 Recon. Range: 65535\n",
            "\n",
            "IED:\n",
            "  ✓ 所有必需列完整\n",
            "  前3行示例:\n",
            "              Timestamp    TargetIP                       Attack  TransactionID\n",
            "2023-03-23 05:09:22.829 185.175.0.2 Baseline Replay: In position              1\n",
            "2023-03-23 05:30:24.984 185.175.0.2 Baseline Replay: In position           1238\n",
            "2023-03-23 05:51:26.274 185.175.0.2 Baseline Replay: In position           2479\n",
            "\n",
            "SCADA:\n",
            "  ✓ 所有必需列完整\n",
            "  前3行示例:\n",
            "              Timestamp    TargetIP                                    Attack  TransactionID\n",
            "2023-03-12 16:12:27.761 185.175.0.4 Brute force or specific coil. Address: 13              5\n",
            "2023-03-12 16:12:27.773 185.175.0.4        Brute force or specific - Complete          65535\n",
            "2023-03-12 16:12:27.774 185.175.0.4 Brute force or specific coil. Address: 14              5\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Investigation 4: CSV Label Quality Comparison Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "#  Read CSV examples from different scenarios\n",
        "csv_samples = {}\n",
        "\n",
        "#  External\n",
        "external_csv_path = glob.glob(os.path.join(config.EXTERNAL_LABELS_DIR, \"**\", \"*.csv\"), recursive=True)\n",
        "if external_csv_path:\n",
        "    csv_samples['External'] = pd.read_csv(external_csv_path[0])\n",
        "\n",
        "#  IED\n",
        "ied_csv_path = glob.glob(os.path.join(config.IED_LABELS_DIR, \"**\", \"*.csv\"), recursive=True)\n",
        "if ied_csv_path:\n",
        "    csv_samples['IED'] = pd.read_csv(ied_csv_path[0])\n",
        "\n",
        "#  SCADA\n",
        "scada_csv_path = glob.glob(os.path.join(config.SCADA_LABELS_DIR, \"**\", \"*.csv\"), recursive=True)\n",
        "if scada_csv_path:\n",
        "    csv_samples['SCADA'] = pd.read_csv(scada_csv_path[0])\n",
        "\n",
        "#  Compare column structures\n",
        "print(\"\\nCSV label column structure comparison:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "comparison = []\n",
        "\n",
        "for scenario, df in csv_samples.items():\n",
        "    comparison.append({\n",
        "        'Scenario': scenario,\n",
        "        'Columns': len(df.columns),\n",
        "        'Column Names': ', '.join(df.columns),\n",
        "        'Has Timestamp': 'Timestamp' in df.columns,\n",
        "        'Has TargetIP': 'TargetIP' in df.columns,\n",
        "        'Has TransactionID': 'TransactionID' in df.columns,\n",
        "        'Has Attack': 'Attack' in df.columns,\n",
        "        'Rows': len(df)\n",
        "    })\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison)\n",
        "print(df_comparison.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Label quality assessment:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for scenario, df in csv_samples.items():\n",
        "    print(f\"\\n{scenario}:\")\n",
        "    \n",
        "    #  Required column check\n",
        "    required_cols = ['Timestamp', 'TargetIP', 'TransactionID', 'Attack']\n",
        "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "    \n",
        "    if missing_cols:\n",
        "        print(f\"  ⚠️  Missing columns: {', '.join(missing_cols)}\")\n",
        "    else:\n",
        "        print(f\"  ✓ All required columns present\")\n",
        "    \n",
        "    #  Show examples\n",
        "    print(f\"  First 3 rows:\")\n",
        "    print(df.head(3).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1dcc9451",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "排查5：IP地址和设备映射验证\n",
            "============================================================\n",
            "\n",
            "官方IP映射:\n",
            "------------------------------------------------------------\n",
            "  185.175.0.4 → IED1A (Secure)\n",
            "  185.175.0.8 → IED4C (Secure)\n",
            "  185.175.0.5 → IED1B (Normal)\n",
            "  185.175.0.2 → SCADA HMI (Secure)\n",
            "  185.175.0.3 → SCADA HMI (Normal)\n",
            "  185.175.0.6 → Central Agent\n",
            "  185.175.0.7 → Attacker\n",
            "\n",
            "从PCAP中验证IP地址...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: Wireshark is installed, but cannot read manuf !\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "测试文件: network-wide-normal-14.pcap\n",
            "\n",
            "观察到的IP地址 (5 个):\n",
            "------------------------------------------------------------\n",
            "✓ 185.175.0.3     → SCADA HMI (Normal)\n",
            "✓ 185.175.0.4     → IED1A (Secure)\n",
            "✓ 185.175.0.5     → IED1B (Normal)\n",
            "✓ 185.175.0.6     → Central Agent\n",
            "✓ 185.175.0.8     → IED4C (Secure)\n",
            "\n",
            "✓ 所有IP地址都在官方映射中\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Investigation 5: IP Address and Device Mapping Verification\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "#  Official documentation IP mapping\n",
        "official_ip_mapping = {\n",
        "    '185.175.0.4': 'IED1A (Secure)',\n",
        "    '185.175.0.8': 'IED4C (Secure)',\n",
        "    '185.175.0.5': 'IED1B (Normal)',\n",
        "    '185.175.0.2': 'SCADA HMI (Secure)',\n",
        "    '185.175.0.3': 'SCADA HMI (Normal)',\n",
        "    '185.175.0.6': 'Central Agent',\n",
        "    '185.175.0.7': 'Attacker'\n",
        "}\n",
        "\n",
        "print(\"\\nOfficial IP mapping:\")\n",
        "print(\"-\" * 60)\n",
        "for ip, device in official_ip_mapping.items():\n",
        "    print(f\"  {ip} → {device}\")\n",
        "\n",
        "#  Extract actual IPs from PCAP\n",
        "print(\"\\nVerifying IP addresses from PCAP...\")\n",
        "from scapy.all import rdpcap, IP\n",
        "\n",
        "#  Read a larger PCAP sample\n",
        "test_pcap = glob.glob(os.path.join(config.BENIGN_PCAP_DIR, \"*.pcap\"))[0]\n",
        "print(f\"Test file: {os.path.basename(test_pcap)}\")\n",
        "\n",
        "packets = rdpcap(test_pcap, count=10000)\n",
        "\n",
        "observed_ips = set()\n",
        "for pkt in packets:\n",
        "    if IP in pkt:\n",
        "        observed_ips.add(pkt[IP].src)\n",
        "        observed_ips.add(pkt[IP].dst)\n",
        "\n",
        "print(f\"\\nObserved IP addresses ({len(observed_ips)}):\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for ip in sorted(observed_ips):\n",
        "    device = official_ip_mapping.get(ip, \"❓ Unknown device\")\n",
        "    marker = \"✓\" if ip in official_ip_mapping else \"⚠️\"\n",
        "    print(f\"{marker} {ip:15s} → {device}\")\n",
        "\n",
        "#  Check for unknown IPs\n",
        "unknown_ips = observed_ips - set(official_ip_mapping.keys())\n",
        "if unknown_ips:\n",
        "    print(f\"\\n⚠️  Found {len(unknown_ips)} unrecorded IP addresses:\")\n",
        "    for ip in unknown_ips:\n",
        "        print(f\"  - {ip}\")\n",
        "else:\n",
        "    print(\"\\n✓ All IP addresses are in official mapping\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "62fbdf4e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "从CSV标签验证TargetIP\n",
            "============================================================\n",
            "\n",
            "External: ⚠️  没有TargetIP列\n",
            "\n",
            "IED CSV中的TargetIP分布:\n",
            "------------------------------------------------------------\n",
            "  185.175.0.2 → SCADA HMI (Secure)        (66 次)\n",
            "\n",
            "SCADA CSV中的TargetIP分布:\n",
            "------------------------------------------------------------\n",
            "  185.175.0.8 → IED4C (Secure)            (49,644 次)\n",
            "  185.175.0.4 → IED1A (Secure)            (33,192 次)\n",
            "  185.175.0.5 → IED1B (Normal)            (24,934 次)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Verifying TargetIP from CSV Labels\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "#  Statistics of TargetIP appearing in CSV\n",
        "target_ips = {}\n",
        "\n",
        "for scenario, df in csv_samples.items():\n",
        "    if 'TargetIP' in df.columns:\n",
        "        ips = df['TargetIP'].value_counts()\n",
        "        target_ips[scenario] = ips\n",
        "        \n",
        "        print(f\"\\n{scenario} CSV TargetIP distribution:\")\n",
        "        print(\"-\" * 60)\n",
        "        for ip, count in ips.items():\n",
        "            device = official_ip_mapping.get(ip, \"❓ Unknown\")\n",
        "            print(f\"  {ip} → {device:25s} ({count:,} times)\")\n",
        "    else:\n",
        "        print(f\"\\n{scenario}: ⚠️  No TargetIP column\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "80b26ecc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "综合诊断报告\n",
            "============================================================\n",
            "\n",
            "⚠️  发现 2 个问题:\n",
            "\n",
            "\n",
            "问题 1:\n",
            "  严重程度: 高\n",
            "  类别: 文件组织\n",
            "  问题描述: 发现 2 个Benign文件在External目录\n",
            "  影响: External PCAP可能包含正常流量，需要过滤\n",
            "  解决方案: 使用IP地址过滤，只保留src_ip=185.175.0.7的包\n",
            "\n",
            "问题 2:\n",
            "  严重程度: 高\n",
            "  类别: CSV标签质量\n",
            "  问题描述: External的CSV缺少TargetIP和TransactionID列\n",
            "  影响: 无法使用三元组匹配，只能用时间窗口匹配\n",
            "  解决方案: 采用IP识别+宽松时间窗口（10秒）\n",
            "\n",
            "✓ 诊断报告已保存: C:\\Users\\Echo\\Desktop\\modbus-detection\\data\\processed\\dataset_quality_report.json\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Comprehensive Diagnostic Report\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "issues = []\n",
        "\n",
        "#  Issue 1: File organization\n",
        "if suspicious_files:\n",
        "    issues.append({\n",
        "        'severity': 'High',\n",
        "        'category': 'File Organization',\n",
        "        'issue': f'Found {len(suspicious_files)} Benign files in External directory',\n",
        "        'impact': 'External PCAP may contain normal traffic, needs filtering',\n",
        "        'solution': 'Use IP address filtering, keep only src_ip=185.175.0.7 packets'\n",
        "    })\n",
        "\n",
        "#  Issue 2: Naming inconsistency\n",
        "if len(naming_patterns['other']) > 0:\n",
        "    issues.append({\n",
        "        'severity': 'Medium',\n",
        "        'category': 'Naming Convention',\n",
        "        'issue': f'Found {len(naming_patterns[\"other\"])} non-standard named files',\n",
        "        'impact': 'File identification difficult, manual check needed',\n",
        "        'solution': 'Create filename → capture type mapping table'\n",
        "    })\n",
        "\n",
        "#  Issue 3: CSV labels incomplete\n",
        "if 'External' in csv_samples:\n",
        "    ext_cols = csv_samples['External'].columns.tolist()\n",
        "    if 'TargetIP' not in ext_cols or 'TransactionID' not in ext_cols:\n",
        "        issues.append({\n",
        "            'severity': 'High',\n",
        "            'category': 'CSV Label Quality',\n",
        "            'issue': 'External CSV missing TargetIP and TransactionID columns',\n",
        "            'impact': 'Cannot use triple matching, can only use time window matching',\n",
        "            'solution': 'Use IP identification + relaxed time window (10 seconds)'\n",
        "        })\n",
        "\n",
        "#  Issue 4: Unknown IP addresses\n",
        "if unknown_ips:\n",
        "    issues.append({\n",
        "        'severity': 'Medium',\n",
        "        'category': 'IP Mapping',\n",
        "        'issue': f'Found {len(unknown_ips)} unrecorded IP addresses',\n",
        "        'impact': 'May be external network addresses or gateways, need identification',\n",
        "        'solution': 'Investigate these IP roles, update mapping table'\n",
        "    })\n",
        "\n",
        "if not issues:\n",
        "    print(\"\\n✅ No serious issues found, dataset quality is good\")\n",
        "else:\n",
        "    print(f\"\\n⚠️  Found {len(issues)} issues:\")\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    for i, issue in enumerate(issues, 1):\n",
        "        print(f\"Issue {i}:\")\n",
        "        print(f\"  Severity: {issue['severity']}\")\n",
        "        print(f\"  Category: {issue['category']}\")\n",
        "        print(f\"  Description: {issue['issue']}\")\n",
        "        print(f\"  Impact: {issue['impact']}\")\n",
        "        print(f\"  Solution: {issue['solution']}\")\n",
        "        print()\n",
        "\n",
        "#  Save diagnostic report\n",
        "import json\n",
        "\n",
        "report = {\n",
        "    'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'total_pcap_files': len(df_pcap),\n",
        "    'total_csv_files': len(df_csv),\n",
        "    'suspicious_files': suspicious_files,\n",
        "    'issues': issues\n",
        "}\n",
        "\n",
        "report_path = config.DATA_PROCESSED / \"dataset_quality_report.json\"\n",
        "with open(report_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(report, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"✓ Diagnostic report saved: {report_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "modbus-detection",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
