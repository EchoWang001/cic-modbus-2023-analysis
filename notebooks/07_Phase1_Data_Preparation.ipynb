{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Data Preparation\n",
        "\n",
        "**Objective**: Complete the data preparation phase for Modbus Anomaly Detection project\n",
        "\n",
        "**Step Overview**:\n",
        "1. Step 1: PCAP File Parsing - Parse all PCAP files to extract Modbus packets\n",
        "2. Step 2: Apply Labeling Policy - Label Attack/Normal based on IP and write operations\n",
        "3. Step 3: 15-Second Window Feature Extraction - Calculate 44 features\n",
        "4. **Step 3.5: Minimum Packet Count Filtering** - Filter windows with packet_count < 30 (ensure feature validity)\n",
        "5. Step 4: Dataset Split - Split into Train/Validation/Test sets by PCAP files\n",
        "\n",
        "**Estimated Duration**: Step 1 takes 4-6 hours, other steps take minutes to 1 hour each\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Environment Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "项目根目录: c:\\Users\\Echo\\Desktop\\modbus-detection\n",
            "src目录: c:\\Users\\Echo\\Desktop\\modbus-detection\\src\n",
            "src目录存在: True\n",
            "当前时间: 2026-01-09 16:36:33\n"
          ]
        }
      ],
      "source": [
        "#   Import dependencies\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#   Setup display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "#   Add src directory to path - use absolute path for correctness\n",
        "PROJECT_ROOT = Path(r\"c:\\Users\\Echo\\Desktop\\modbus-detection\")\n",
        "SRC_DIR = PROJECT_ROOT / 'src'\n",
        "\n",
        "#   Ensure src directory is in Python path\n",
        "if str(SRC_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(SRC_DIR))\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"src directory: {SRC_DIR}\")\n",
        "print(f\"src directory exists: {SRC_DIR.exists()}\")\n",
        "print(f\"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ 所有目录已创建\n",
            "✓ 模块导入成功\n"
          ]
        }
      ],
      "source": [
        "#   Import project modules\n",
        "import config\n",
        "from pcap_parser import (\n",
        "    ModbusPacketParser, \n",
        "    scan_pcap_files, \n",
        "    parse_all_pcaps,\n",
        "    save_packets_to_parquet,\n",
        "    load_packets_from_parquet\n",
        ")\n",
        "from feature_extractor import (\n",
        "    extract_window_features,\n",
        "    get_feature_names,\n",
        "    get_feature_groups,\n",
        "    ATTACKER_IP,\n",
        "    WRITE_FCS\n",
        ")\n",
        "\n",
        "#   Ensure directories exist\n",
        "config.ensure_dirs()\n",
        "\n",
        "print(\"✓ Modules imported successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "配置参数:\n",
            "  time_window: 15\n",
            "  random_seed: 42\n",
            "  split_ratios: {'train': 0.7, 'val': 0.15, 'test': 0.15}\n",
            "\n",
            "输出路径:\n",
            "  packets_raw: c:\\Users\\Echo\\Desktop\\modbus-detection\\data\\processed\\packets_raw.parquet\n",
            "  packets_labeled: c:\\Users\\Echo\\Desktop\\modbus-detection\\data\\processed\\packets_labeled.parquet\n",
            "  features_15s: c:\\Users\\Echo\\Desktop\\modbus-detection\\data\\processed\\features_15s.parquet\n",
            "  train: c:\\Users\\Echo\\Desktop\\modbus-detection\\data\\splits\\train.parquet\n",
            "  val: c:\\Users\\Echo\\Desktop\\modbus-detection\\data\\splits\\val.parquet\n",
            "  test: c:\\Users\\Echo\\Desktop\\modbus-detection\\data\\splits\\test.parquet\n",
            "  split_info: c:\\Users\\Echo\\Desktop\\modbus-detection\\data\\splits\\split_info.json\n"
          ]
        }
      ],
      "source": [
        "#   Configuration parameters\n",
        "PARAMS = {\n",
        "    'time_window': 15,  #   Seconds, main experiment window size\n",
        "    'random_seed': 42,\n",
        "    'split_ratios': {\n",
        "        'train': 0.70,\n",
        "        'val': 0.15,\n",
        "        'test': 0.15\n",
        "    }\n",
        "}\n",
        "\n",
        "#   Output file paths\n",
        "OUTPUT_PATHS = {\n",
        "    'packets_raw': config.DATA_PROCESSED / 'packets_raw.parquet',\n",
        "    'packets_labeled': config.DATA_PROCESSED / 'packets_labeled.parquet',\n",
        "    'features_15s': config.DATA_PROCESSED / 'features_15s.parquet',\n",
        "    'train': config.DATA_SPLITS / 'train.parquet',\n",
        "    'val': config.DATA_SPLITS / 'val.parquet',\n",
        "    'test': config.DATA_SPLITS / 'test.parquet',\n",
        "    'split_info': config.DATA_SPLITS / 'split_info.json'\n",
        "}\n",
        "\n",
        "print(\"Configuration parameters:\")\n",
        "for k, v in PARAMS.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n",
        "print(\"\\nOutput paths:\")\n",
        "for k, v in OUTPUT_PATHS.items():\n",
        "    print(f\"  {k}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "数据集路径检查:\n",
            "  数据集根目录: C:\\Users\\Echo\\Desktop\\Modbus Dataset\\Modbus Dataset\n",
            "  存在: True\n",
            "\n",
            "PCAP目录检查:\n",
            "  ✓ Benign: 19 个PCAP文件\n",
            "  ✓ External: 1 个PCAP文件\n",
            "  ✓ SCADA: 18 个PCAP文件\n",
            "  ✓ IED: 6 个PCAP文件\n"
          ]
        }
      ],
      "source": [
        "#   Check dataset paths\n",
        "print(\"Dataset path check:\")\n",
        "print(f\"  Dataset root: {config.DATASET_ROOT}\")\n",
        "print(f\"  Exists: {os.path.exists(config.DATASET_ROOT)}\")\n",
        "\n",
        "print(\"\\nPCAP directory check:\")\n",
        "pcap_dirs = {\n",
        "    'Benign': config.BENIGN_PCAP_DIR,\n",
        "    'External': config.EXTERNAL_PCAP_DIR,\n",
        "    'SCADA': config.SCADA_PCAP_DIR,\n",
        "    'IED': config.IED_PCAP_DIR\n",
        "}\n",
        "\n",
        "for name, path in pcap_dirs.items():\n",
        "    exists = os.path.exists(path)\n",
        "    file_count = len(glob.glob(os.path.join(path, '*.pcap'))) if exists else 0\n",
        "    status = \"✓\" if exists else \"✗\"\n",
        "    print(f\"  {status} {name}: {file_count} PCAP files\")\n",
        "    if not exists:\n",
        "        print(f\"     Path: {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 1. Step 1: PCAP File Parsing\n",
        "\n",
        "**Objective**: Parse all PCAP files to extract Modbus packet data\n",
        "\n",
        "**Output**: `packets_raw.parquet`\n",
        "\n",
        "**Estimated Duration**: 4-6 hours (can run overnight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Scanning All PCAP Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-09 16:36:40,967 - INFO - 在 benign 目录找到 19 个PCAP文件\n",
            "2026-01-09 16:36:40,969 - INFO - 在 external 目录找到 1 个PCAP文件\n",
            "2026-01-09 16:36:40,970 - INFO - 在 scada 目录找到 18 个PCAP文件\n",
            "2026-01-09 16:36:40,971 - INFO - 在 ied 目录找到 6 个PCAP文件\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "PCAP文件统计:\n",
            "  Benign: 19\n",
            "  External: 1\n",
            "  SCADA: 18\n",
            "  IED: 6\n",
            "  总计: 44\n"
          ]
        }
      ],
      "source": [
        "#   Scan PCAP files from each scenario\n",
        "benign_files = scan_pcap_files(config.BENIGN_PCAP_DIR, 'benign')\n",
        "external_files = scan_pcap_files(config.EXTERNAL_PCAP_DIR, 'external')\n",
        "scada_files = scan_pcap_files(config.SCADA_PCAP_DIR, 'scada')\n",
        "ied_files = scan_pcap_files(config.IED_PCAP_DIR, 'ied')\n",
        "\n",
        "#   Merge all files\n",
        "all_pcap_files = benign_files + external_files + scada_files + ied_files\n",
        "\n",
        "print(\"\\nPCAP file statistics:\")\n",
        "print(f\"  Benign: {len(benign_files)}\")\n",
        "print(f\"  External: {len(external_files)}\")\n",
        "print(f\"  SCADA: {len(scada_files)}\")\n",
        "print(f\"  IED: {len(ied_files)}\")\n",
        "print(f\"  Total: {len(all_pcap_files)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Benign文件示例:\n",
            "  network-wide-normal-14.pcap\n",
            "  network-wide-normal-15.pcap\n",
            "  network-wide-normal-16.pcap\n",
            "\n",
            "External文件示例:\n",
            "  veth665f3cf-0.pcap\n"
          ]
        }
      ],
      "source": [
        "#   View file list examples\n",
        "print(\"Benign file examples:\")\n",
        "for f, s in benign_files[:3]:\n",
        "    print(f\"  {os.path.basename(f)}\")\n",
        "\n",
        "print(\"\\nExternal file examples:\")\n",
        "for f, s in external_files[:5]:\n",
        "    print(f\"  {os.path.basename(f)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Parse PCAP Files\n",
        "\n",
        "⚠️ **Note**: This step takes a long time (4-6 hours), recommend running overnight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "未发现已有解析结果，将开始解析...\n"
          ]
        }
      ],
      "source": [
        "#   Check if parsed results already exist\n",
        "if OUTPUT_PATHS['packets_raw'].exists():\n",
        "    print(f\"✓ Found existing parsed results: {OUTPUT_PATHS['packets_raw']}\")\n",
        "    print(\"  To re-parse, delete this file and run again\")\n",
        "    \n",
        "    #   Load existing data\n",
        "    df_packets_raw = load_packets_from_parquet(str(OUTPUT_PATHS['packets_raw']))\n",
        "    SKIP_PARSING = True\n",
        "else:\n",
        "    print(\"No existing parsed results found, will start parsing...\")\n",
        "    SKIP_PARSING = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "开始解析 44 个PCAP文件...\n",
            "开始时间: 2026-01-09 15:11:57\n",
            "预计耗时: 4-6小时\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "解析PCAP文件:   0%|          | 0/44 [00:24<?, ?it/s]\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": []
        }
      ],
      "source": [
        "#   Execute parsing (if needed)\n",
        "if not SKIP_PARSING:\n",
        "    print(f\"Starting to parse {len(all_pcap_files)} PCAP files...\")\n",
        "    print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(\"Estimated time: 4-6 hours\\n\")\n",
        "    \n",
        "    #   Create parser\n",
        "    parser = ModbusPacketParser(strict_mode=True)\n",
        "    \n",
        "    #   Batch parsing\n",
        "    df_packets_raw = parse_all_pcaps(all_pcap_files, parser, show_progress=True)\n",
        "    \n",
        "    print(f\"\\nCompletion time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"Parsing result: {len(df_packets_raw):,} records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": []
        }
      ],
      "source": [
        "#   Save raw data\n",
        "if not SKIP_PARSING:\n",
        "    save_packets_to_parquet(df_packets_raw, str(OUTPUT_PATHS['packets_raw']))\n",
        "    print(\"✓ Raw data saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ 数据已保存为CSV: c:\\Users\\Echo\\Desktop\\modbus-detection\\data\\processed\\packets_raw.csv\n",
            "  记录数: 8,478,926\n"
          ]
        }
      ],
      "source": [
        "#   Emergency save - use CSV format (no pyarrow needed)\n",
        "csv_path = str(OUTPUT_PATHS['packets_raw']).replace('.parquet', '.csv')\n",
        "df_packets_raw.to_csv(csv_path, index=False)\n",
        "print(f\"✓ Data saved as CSV: {csv_path}\")\n",
        "print(f\"  Records: {len(df_packets_raw):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "从CSV加载数据: c:\\Users\\Echo\\Desktop\\modbus-detection\\data\\processed\\packets_raw.csv\n",
            "✓ 数据已加载: 8,478,926 条记录\n",
            "\n",
            "场景分布:\n",
            "scenario\n",
            "benign      3953147\n",
            "scada       3344142\n",
            "ied         1116026\n",
            "external      65611\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#   Load already parsed data from CSV (skip 3 hours of parsing)\n",
        "import pandas as pd\n",
        "\n",
        "csv_path = config.DATA_PROCESSED / 'packets_raw.csv'\n",
        "print(f\"Loading data from CSV: {csv_path}\")\n",
        "\n",
        "df_packets_raw = pd.read_csv(csv_path)\n",
        "df_packets_raw['timestamp'] = pd.to_datetime(df_packets_raw['timestamp'])\n",
        "\n",
        "print(f\"✓ Data loaded: {len(df_packets_raw):,} records\")\n",
        "print(f\"\\nScenario distribution:\")\n",
        "print(df_packets_raw['scenario'].value_counts())\n",
        "\n",
        "#   Set flag to skip parsing\n",
        "SKIP_PARSING = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Data Quality Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#   Basic info\n",
        "print(\"Raw data overview:\")\n",
        "print(f\"  Total records: {len(df_packets_raw):,}\")\n",
        "print(f\"  Columns: {len(df_packets_raw.columns)}\")\n",
        "print(f\"  Column names: {list(df_packets_raw.columns)}\")\n",
        "\n",
        "print(\"\\nData types:\")\n",
        "print(df_packets_raw.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#   Scenario distribution\n",
        "print(\"Scenario distribution:\")\n",
        "scenario_counts = df_packets_raw['scenario'].value_counts()\n",
        "for scenario, count in scenario_counts.items():\n",
        "    pct = count / len(df_packets_raw) * 100\n",
        "    print(f\"  {scenario}: {count:,} ({pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#   Function code distribution\n",
        "print(\"Function code distribution:\")\n",
        "fc_counts = df_packets_raw['function_code'].value_counts().sort_index()\n",
        "for fc, count in fc_counts.items():\n",
        "    pct = count / len(df_packets_raw) * 100\n",
        "    fc_type = 'Write' if fc in WRITE_FCS else 'Read'\n",
        "    print(f\"  FC {fc:2d} ({fc_type}): {count:,} ({pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#   IP address distribution\n",
        "print(\"Source IP distribution:\")\n",
        "src_ip_counts = df_packets_raw['src_ip'].value_counts()\n",
        "for ip, count in src_ip_counts.head(10).items():\n",
        "    pct = count / len(df_packets_raw) * 100\n",
        "    print(f\"  {ip}: {count:,} ({pct:.1f}%)\")\n",
        "\n",
        "print(\"\\nDestination IP distribution:\")\n",
        "dst_ip_counts = df_packets_raw['dst_ip'].value_counts()\n",
        "for ip, count in dst_ip_counts.head(10).items():\n",
        "    pct = count / len(df_packets_raw) * 100\n",
        "    print(f\"  {ip}: {count:,} ({pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#   Check missing values\n",
        "print(\"Missing value statistics:\")\n",
        "missing = df_packets_raw.isnull().sum()\n",
        "for col, count in missing.items():\n",
        "    if count > 0:\n",
        "        pct = count / len(df_packets_raw) * 100\n",
        "        print(f\"  {col}: {count:,} ({pct:.1f}%)\")\n",
        "\n",
        "if missing.sum() == 0:\n",
        "    print(\"  No missing values (except start_address and quantity, which is expected)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#   Data sample\n",
        "print(\"Data sample (first 5 rows):\")\n",
        "df_packets_raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. Step 2: Apply Labeling Policy\n",
        "\n",
        "**Objective**: Label each packet according to design document labeling policy\n",
        "\n",
        "**Labeling Rules**:\n",
        "- Benign: All packets → Normal\n",
        "- External: src_ip == 185.175.0.7 → Attack, others → Normal\n",
        "- Compromised (SCADA/IED): Write operations (FC 5/6/15/16) → marked, final label determined at window level\n",
        "\n",
        "**Output**: `packets_labeled.parquet`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ 标签列已初始化\n"
          ]
        }
      ],
      "source": [
        "#   Copy data\n",
        "df_labeled = df_packets_raw.copy()\n",
        "\n",
        "#   Initialize label columns\n",
        "df_labeled['is_write_operation'] = df_labeled['function_code'].isin(WRITE_FCS)\n",
        "df_labeled['is_external_attacker'] = df_labeled['src_ip'] == ATTACKER_IP\n",
        "df_labeled['packet_label'] = 'unknown'\n",
        "\n",
        "print(\"✓ Label columns initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Benign场景: 3,953,147 包 → Normal\n"
          ]
        }
      ],
      "source": [
        "#   Apply Benign scenario labels\n",
        "benign_mask = df_labeled['scenario'] == 'benign'\n",
        "df_labeled.loc[benign_mask, 'packet_label'] = 'normal'\n",
        "\n",
        "print(f\"Benign scenario: {benign_mask.sum():,} packets → Normal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "External场景:\n",
            "  Attack (src_ip=185.175.0.7): 65,611 包\n",
            "  Normal (其他IP): 0 包\n"
          ]
        }
      ],
      "source": [
        "#   Apply External scenario labels (IP filtering)\n",
        "external_mask = df_labeled['scenario'] == 'external'\n",
        "external_attack_mask = external_mask & df_labeled['is_external_attacker']\n",
        "external_normal_mask = external_mask & ~df_labeled['is_external_attacker']\n",
        "\n",
        "df_labeled.loc[external_attack_mask, 'packet_label'] = 'attack'\n",
        "df_labeled.loc[external_normal_mask, 'packet_label'] = 'normal'\n",
        "\n",
        "print(f\"External scenario:\")\n",
        "print(f\"  Attack (src_ip={ATTACKER_IP}): {external_attack_mask.sum():,} packets\")\n",
        "print(f\"  Normal (other IPs): {external_normal_mask.sum():,} packets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compromised场景 (SCADA + IED): 4,460,168 包 → attack_env\n",
            "  其中写操作包: 521,693\n"
          ]
        }
      ],
      "source": [
        "#   Apply Compromised scenario labels (write operation marking)\n",
        "#   Note: Mark as 'attack_env' first, final label determined at window level\n",
        "compromised_mask = df_labeled['scenario'].isin(['scada', 'ied'])\n",
        "df_labeled.loc[compromised_mask, 'packet_label'] = 'attack_env'\n",
        "\n",
        "print(f\"Compromised scenario (SCADA + IED): {compromised_mask.sum():,} packets → attack_env\")\n",
        "print(f\"  Write operation packets: {(compromised_mask & df_labeled['is_write_operation']).sum():,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "包级别标签分布:\n",
            "  attack_env: 4,460,168 (52.6%)\n",
            "  normal: 3,953,147 (46.6%)\n",
            "  attack: 65,611 (0.8%)\n"
          ]
        }
      ],
      "source": [
        "#   Label distribution statistics\n",
        "print(\"Packet-level label distribution:\")\n",
        "label_counts = df_labeled['packet_label'].value_counts()\n",
        "for label, count in label_counts.items():\n",
        "    pct = count / len(df_labeled) * 100\n",
        "    print(f\"  {label}: {count:,} ({pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-09 15:11:49,508 - INFO - 数据已保存: c:\\Users\\Echo\\Desktop\\modbus-detection\\data\\processed\\packets_labeled.parquet\n",
            "2026-01-09 15:11:49,510 - INFO -   - 记录数: 8,478,926\n",
            "2026-01-09 15:11:49,511 - INFO -   - 文件大小: 103.38 MB\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ 标记后数据已保存\n"
          ]
        }
      ],
      "source": [
        "#   Save labeled data\n",
        "save_packets_to_parquet(df_labeled, str(OUTPUT_PATHS['packets_labeled']))\n",
        "print(\"✓ Labeled data saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Step 3: 15-Second Window Feature Extraction\n",
        "\n",
        "**Objective**: Aggregate packet-level data into 15-second windows, calculate 44 features\n",
        "\n",
        "**Window Labeling Rules**:\n",
        "- Benign windows: Normal\n",
        "- External windows: Has attacker IP → Attack, otherwise → Normal\n",
        "- Compromised windows: Has write operations → Attack, otherwise → Normal\n",
        "\n",
        "**Output**: `features_15s.parquet`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "特征总数: 44\n",
            "\n",
            "特征分组:\n",
            "  protocol: 13个\n",
            "  temporal: 9个\n",
            "  dcs_device_role: 6个\n",
            "  dcs_topology: 5个\n",
            "  dcs_operation: 6个\n",
            "  dcs_anomaly: 5个\n"
          ]
        }
      ],
      "source": [
        "#   Feature info\n",
        "feature_names = get_feature_names()\n",
        "feature_groups = get_feature_groups()\n",
        "\n",
        "print(f\"Total features: {len(feature_names)}\")\n",
        "print(\"\\nFeature groups:\")\n",
        "for group, features in feature_groups.items():\n",
        "    print(f\"  {group}: {len(features)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "分组数: 43\n"
          ]
        }
      ],
      "source": [
        "#   Ensure timestamp is datetime type\n",
        "df_labeled['timestamp'] = pd.to_datetime(df_labeled['timestamp'])\n",
        "\n",
        "#   Group by scenario and file\n",
        "grouped = df_labeled.groupby(['scenario', 'pcap_file'])\n",
        "print(f\"Number of groups: {len(grouped)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_windows(df_file, window_size_sec=15):\n",
        "    \"\"\"\n",
        "    Split a single file's data into time windows\n",
        "    \n",
        "    Args:\n",
        "        df_file: Data from a single PCAP file\n",
        "        window_size_sec: Window size (seconds)\n",
        "    \n",
        "    Returns:\n",
        "        List of windows, each window is a DataFrame\n",
        "    \"\"\"\n",
        "    if len(df_file) == 0:\n",
        "        return []\n",
        "    \n",
        "    #   Sort by time\n",
        "    df_sorted = df_file.sort_values('timestamp')\n",
        "    \n",
        "    #   Get time range\n",
        "    start_time = df_sorted['timestamp'].min()\n",
        "    end_time = df_sorted['timestamp'].max()\n",
        "    \n",
        "    #   Create windows\n",
        "    windows = []\n",
        "    current_start = start_time\n",
        "    window_delta = pd.Timedelta(seconds=window_size_sec)\n",
        "    \n",
        "    while current_start < end_time:\n",
        "        current_end = current_start + window_delta\n",
        "        \n",
        "        #   Filter packets within window\n",
        "        mask = (df_sorted['timestamp'] >= current_start) & (df_sorted['timestamp'] < current_end)\n",
        "        window_df = df_sorted[mask]\n",
        "        \n",
        "        if len(window_df) > 0:\n",
        "            windows.append({\n",
        "                'window_start': current_start,\n",
        "                'window_end': current_end,\n",
        "                'data': window_df\n",
        "            })\n",
        "        \n",
        "        current_start = current_end\n",
        "    \n",
        "    return windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def determine_window_label(window_df, scenario):\n",
        "    \"\"\"\n",
        "    Determine window label\n",
        "    \n",
        "    Args:\n",
        "        window_df: Packet data within window\n",
        "        scenario: Scenario identifier\n",
        "    \n",
        "    Returns:\n",
        "        'Attack' or 'Normal'\n",
        "    \"\"\"\n",
        "    if scenario == 'benign':\n",
        "        return 'Normal'\n",
        "    \n",
        "    elif scenario == 'external':\n",
        "        #   External: Has attacker IP → Attack\n",
        "        if window_df['is_external_attacker'].any():\n",
        "            return 'Attack'\n",
        "        else:\n",
        "            return 'Normal'\n",
        "    \n",
        "    elif scenario in ['scada', 'ied']:\n",
        "        #   Compromised: Has write operations → Attack\n",
        "        if window_df['is_write_operation'].any():\n",
        "            return 'Attack'\n",
        "        else:\n",
        "            return 'Normal'\n",
        "    \n",
        "    else:\n",
        "        return 'Unknown'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "开始提取15秒窗口特征...\n",
            "开始时间: 2026-01-09 15:13:27\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e17d980282f4e178f310f71a973a27f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "处理文件:   0%|          | 0/43 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "完成时间: 2026-01-09 15:50:55\n",
            "总窗口数: 121934\n"
          ]
        }
      ],
      "source": [
        "#   Extract features for all windows\n",
        "print(f\"Starting 15-second window feature extraction...\")\n",
        "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "all_window_features = []\n",
        "window_size = PARAMS['time_window']\n",
        "\n",
        "for (scenario, pcap_file), df_file in tqdm(grouped, desc=\"Processing files\"):\n",
        "    #   Split into windows\n",
        "    windows = create_windows(df_file, window_size_sec=window_size)\n",
        "    \n",
        "    for window in windows:\n",
        "        window_df = window['data']\n",
        "        \n",
        "        #   Extract features\n",
        "        features = extract_window_features(window_df, window_size)\n",
        "        \n",
        "        #   Add metadata\n",
        "        features['scenario'] = scenario\n",
        "        features['pcap_file'] = pcap_file\n",
        "        features['window_start'] = window['window_start']\n",
        "        features['window_end'] = window['window_end']\n",
        "        features['packet_count_raw'] = len(window_df)  #   Raw packet count (should match packet_count in features)\n",
        "        \n",
        "        #   Determine window label\n",
        "        features['label'] = determine_window_label(window_df, scenario)\n",
        "        \n",
        "        all_window_features.append(features)\n",
        "\n",
        "print(f\"\\nCompletion time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Total windows: {len(all_window_features)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "特征数据集形状: (121934, 50)\n",
            "列数: 50 (44个特征 + 6个元数据)\n"
          ]
        }
      ],
      "source": [
        "#   Convert to DataFrame\n",
        "df_features = pd.DataFrame(all_window_features)\n",
        "\n",
        "print(f\"Feature dataset shape: {df_features.shape}\")\n",
        "print(f\"Columns: {len(df_features.columns)} (44 features + 6 metadata)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-09 15:52:15,295 - INFO - 数据已保存: c:\\Users\\Echo\\Desktop\\modbus-detection\\data\\processed\\features_15s.parquet\n",
            "2026-01-09 15:52:15,296 - INFO -   - 记录数: 121,934\n",
            "2026-01-09 15:52:15,297 - INFO -   - 文件大小: 7.55 MB\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ 特征数据已保存\n"
          ]
        }
      ],
      "source": [
        "#   Save feature data\n",
        "save_packets_to_parquet(df_features, str(OUTPUT_PATHS['features_15s']))\n",
        "print(\"✓ Feature data saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Feature Dataset Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "窗口级标签分布:\n",
            "  Normal: 116,587 (95.6%)\n",
            "  Attack: 5,347 (4.4%)\n",
            "\n",
            "类别比例 (Normal:Attack): 116587:5347\n",
            "  比例: 21.8:1\n"
          ]
        }
      ],
      "source": [
        "#   Label distribution\n",
        "print(\"Window-level label distribution:\")\n",
        "label_counts = df_features['label'].value_counts()\n",
        "for label, count in label_counts.items():\n",
        "    pct = count / len(df_features) * 100\n",
        "    print(f\"  {label}: {count:,} ({pct:.1f}%)\")\n",
        "\n",
        "print(f\"\\nClass ratio (Normal:Attack): {label_counts.get('Normal', 0)}:{label_counts.get('Attack', 0)}\")\n",
        "if label_counts.get('Attack', 0) > 0:\n",
        "    ratio = label_counts.get('Normal', 0) / label_counts.get('Attack', 0)\n",
        "    print(f\"  Ratio: {ratio:.1f}:1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "场景分布:\n",
            "  benign: 44,904 (36.8%)\n",
            "  scada: 39,137 (32.1%)\n",
            "  ied: 37,846 (31.0%)\n",
            "  external: 47 (0.0%)\n"
          ]
        }
      ],
      "source": [
        "#   Scenario distribution\n",
        "print(\"Scenario distribution:\")\n",
        "scenario_counts = df_features['scenario'].value_counts()\n",
        "for scenario, count in scenario_counts.items():\n",
        "    pct = count / len(df_features) * 100\n",
        "    print(f\"  {scenario}: {count:,} ({pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "场景 × 标签交叉表:\n",
            "label     Attack  Normal\n",
            "scenario                \n",
            "benign         0   44904\n",
            "external      47       0\n",
            "ied         1487   36359\n",
            "scada       3813   35324\n"
          ]
        }
      ],
      "source": [
        "#   Scenario × Label cross table\n",
        "print(\"Scenario × Label cross table:\")\n",
        "cross_tab = pd.crosstab(df_features['scenario'], df_features['label'])\n",
        "print(cross_tab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "特征统计描述:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fc_distribution_entropy</th>\n",
              "      <th>fc_diversity</th>\n",
              "      <th>fc_read_ratio</th>\n",
              "      <th>fc_write_ratio</th>\n",
              "      <th>txid_mean</th>\n",
              "      <th>txid_std</th>\n",
              "      <th>txid_unique_ratio</th>\n",
              "      <th>unit_id_diversity</th>\n",
              "      <th>packet_size_mean</th>\n",
              "      <th>packet_size_std</th>\n",
              "      <th>address_range</th>\n",
              "      <th>value_mean</th>\n",
              "      <th>value_std</th>\n",
              "      <th>packet_count</th>\n",
              "      <th>packet_rate</th>\n",
              "      <th>interval_mean</th>\n",
              "      <th>interval_std</th>\n",
              "      <th>interval_min</th>\n",
              "      <th>interval_max</th>\n",
              "      <th>burst_count</th>\n",
              "      <th>burst_intensity</th>\n",
              "      <th>session_count</th>\n",
              "      <th>scada_src_ratio</th>\n",
              "      <th>scada_dst_ratio</th>\n",
              "      <th>ied_src_ratio</th>\n",
              "      <th>ied_dst_ratio</th>\n",
              "      <th>device_role_entropy</th>\n",
              "      <th>is_typical_scada_to_ied</th>\n",
              "      <th>src_ip_count</th>\n",
              "      <th>dst_ip_count</th>\n",
              "      <th>comm_pair_count</th>\n",
              "      <th>dominant_pair_ratio</th>\n",
              "      <th>multi_target_ratio</th>\n",
              "      <th>consecutive_write_max</th>\n",
              "      <th>consecutive_write_mean</th>\n",
              "      <th>write_burst_count</th>\n",
              "      <th>read_write_alternation</th>\n",
              "      <th>operation_sequence_entropy</th>\n",
              "      <th>write_without_read_ratio</th>\n",
              "      <th>external_ip_present</th>\n",
              "      <th>external_ip_packet_ratio</th>\n",
              "      <th>unknown_ip_count</th>\n",
              "      <th>abnormal_fc_ratio</th>\n",
              "      <th>address_range_exceeded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.0</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.0</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.00000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.000000</td>\n",
              "      <td>121934.0</td>\n",
              "      <td>121934.0</td>\n",
              "      <td>121934.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.931346</td>\n",
              "      <td>4.085308</td>\n",
              "      <td>0.993173</td>\n",
              "      <td>0.006827</td>\n",
              "      <td>31337.756516</td>\n",
              "      <td>9668.896077</td>\n",
              "      <td>0.500986</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.224371</td>\n",
              "      <td>0.921551</td>\n",
              "      <td>42.766513</td>\n",
              "      <td>9.931757</td>\n",
              "      <td>23.360324</td>\n",
              "      <td>69.537012</td>\n",
              "      <td>4.635801</td>\n",
              "      <td>0.221806</td>\n",
              "      <td>0.831613</td>\n",
              "      <td>0.000233</td>\n",
              "      <td>3.997519</td>\n",
              "      <td>5.315810</td>\n",
              "      <td>11.913992</td>\n",
              "      <td>4.492250</td>\n",
              "      <td>0.504437</td>\n",
              "      <td>0.495178</td>\n",
              "      <td>0.495178</td>\n",
              "      <td>0.504822</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.999615</td>\n",
              "      <td>3.187995</td>\n",
              "      <td>3.303820</td>\n",
              "      <td>4.492250</td>\n",
              "      <td>0.297255</td>\n",
              "      <td>0.18516</td>\n",
              "      <td>2.710097</td>\n",
              "      <td>1.321608</td>\n",
              "      <td>0.021741</td>\n",
              "      <td>0.003931</td>\n",
              "      <td>0.022482</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>0.000385</td>\n",
              "      <td>0.000385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.105305</td>\n",
              "      <td>0.318107</td>\n",
              "      <td>0.053328</td>\n",
              "      <td>0.053328</td>\n",
              "      <td>14207.371705</td>\n",
              "      <td>7884.634178</td>\n",
              "      <td>0.034179</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.287931</td>\n",
              "      <td>1.173410</td>\n",
              "      <td>348.148140</td>\n",
              "      <td>413.147931</td>\n",
              "      <td>488.688594</td>\n",
              "      <td>129.013854</td>\n",
              "      <td>8.600924</td>\n",
              "      <td>0.104192</td>\n",
              "      <td>0.317174</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.968254</td>\n",
              "      <td>2.230681</td>\n",
              "      <td>45.819743</td>\n",
              "      <td>1.821498</td>\n",
              "      <td>0.027270</td>\n",
              "      <td>0.027205</td>\n",
              "      <td>0.027205</td>\n",
              "      <td>0.027205</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019629</td>\n",
              "      <td>0.930113</td>\n",
              "      <td>0.928247</td>\n",
              "      <td>1.821498</td>\n",
              "      <td>0.154616</td>\n",
              "      <td>0.13683</td>\n",
              "      <td>92.511626</td>\n",
              "      <td>75.384169</td>\n",
              "      <td>0.448722</td>\n",
              "      <td>0.016487</td>\n",
              "      <td>0.087763</td>\n",
              "      <td>0.008591</td>\n",
              "      <td>0.019629</td>\n",
              "      <td>0.019629</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002828</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.782609</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.921928</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>21300.515625</td>\n",
              "      <td>4.320494</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>0.871780</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.133548</td>\n",
              "      <td>0.574454</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>3.177913</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.921928</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31322.827381</td>\n",
              "      <td>11628.714604</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>0.871780</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>5.333333</td>\n",
              "      <td>0.161496</td>\n",
              "      <td>0.673596</td>\n",
              "      <td>0.000235</td>\n",
              "      <td>4.117591</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.25000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.921928</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40797.511905</td>\n",
              "      <td>16306.956968</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>0.871780</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.354726</td>\n",
              "      <td>1.265617</td>\n",
              "      <td>0.000290</td>\n",
              "      <td>5.006182</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.25000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.418296</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>65525.000000</td>\n",
              "      <td>32691.359547</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>60.472216</td>\n",
              "      <td>10282.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>22609.628676</td>\n",
              "      <td>12639.000000</td>\n",
              "      <td>842.600000</td>\n",
              "      <td>2.006494</td>\n",
              "      <td>3.765320</td>\n",
              "      <td>0.014887</td>\n",
              "      <td>11.823034</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>8800.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>12639.000000</td>\n",
              "      <td>12639.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.178571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232558</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       fc_distribution_entropy   fc_diversity  fc_read_ratio  fc_write_ratio  \\\n",
              "count            121934.000000  121934.000000  121934.000000   121934.000000   \n",
              "mean                  1.931346       4.085308       0.993173        0.006827   \n",
              "std                   0.105305       0.318107       0.053328        0.053328   \n",
              "min                   0.000000       1.000000       0.000000        0.000000   \n",
              "25%                   1.921928       4.000000       1.000000        0.000000   \n",
              "50%                   1.921928       4.000000       1.000000        0.000000   \n",
              "75%                   1.921928       4.000000       1.000000        0.000000   \n",
              "max                   2.418296       6.000000       1.000000        1.000000   \n",
              "\n",
              "           txid_mean       txid_std  txid_unique_ratio  unit_id_diversity  \\\n",
              "count  121934.000000  121934.000000      121934.000000           121934.0   \n",
              "mean    31337.756516    9668.896077           0.500986                1.0   \n",
              "std     14207.371705    7884.634178           0.034179                0.0   \n",
              "min         0.000000       0.000000           0.002828                1.0   \n",
              "25%     21300.515625       4.320494           0.500000                1.0   \n",
              "50%     31322.827381   11628.714604           0.500000                1.0   \n",
              "75%     40797.511905   16306.956968           0.500000                1.0   \n",
              "max     65525.000000   32691.359547           1.000000                1.0   \n",
              "\n",
              "       packet_size_mean  packet_size_std  address_range     value_mean  \\\n",
              "count     121934.000000    121934.000000  121934.000000  121934.000000   \n",
              "mean          11.224371         0.921551      42.766513       9.931757   \n",
              "std            0.287931         1.173410     348.148140     413.147931   \n",
              "min           10.782609         0.000000       0.000000       0.000000   \n",
              "25%           11.200000         0.871780      30.000000       1.000000   \n",
              "50%           11.200000         0.871780      30.000000       1.000000   \n",
              "75%           11.200000         0.871780      30.000000       1.000000   \n",
              "max           26.666667        60.472216   10282.000000   65535.000000   \n",
              "\n",
              "           value_std   packet_count    packet_rate  interval_mean  \\\n",
              "count  121934.000000  121934.000000  121934.000000  121934.000000   \n",
              "mean       23.360324      69.537012       4.635801       0.221806   \n",
              "std       488.688594     129.013854       8.600924       0.104192   \n",
              "min         0.000000       1.000000       0.066667       0.000000   \n",
              "25%         0.000000      30.000000       2.000000       0.133548   \n",
              "50%         0.000000      80.000000       5.333333       0.161496   \n",
              "75%         0.000000      90.000000       6.000000       0.354726   \n",
              "max     22609.628676   12639.000000     842.600000       2.006494   \n",
              "\n",
              "        interval_std   interval_min   interval_max    burst_count  \\\n",
              "count  121934.000000  121934.000000  121934.000000  121934.000000   \n",
              "mean        0.831613       0.000233       3.997519       5.315810   \n",
              "std         0.317174       0.000125       0.968254       2.230681   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.574454       0.000178       3.177913       3.000000   \n",
              "50%         0.673596       0.000235       4.117591       6.000000   \n",
              "75%         1.265617       0.000290       5.006182       6.000000   \n",
              "max         3.765320       0.014887      11.823034      24.000000   \n",
              "\n",
              "       burst_intensity  session_count  scada_src_ratio  scada_dst_ratio  \\\n",
              "count    121934.000000  121934.000000    121934.000000    121934.000000   \n",
              "mean         11.913992       4.492250         0.504437         0.495178   \n",
              "std          45.819743       1.821498         0.027270         0.027205   \n",
              "min           0.000000       1.000000         0.000000         0.000000   \n",
              "25%           9.000000       2.000000         0.500000         0.500000   \n",
              "50%           9.000000       6.000000         0.500000         0.500000   \n",
              "75%          14.000000       6.000000         0.500000         0.500000   \n",
              "max        8800.000000       6.000000         1.000000         1.000000   \n",
              "\n",
              "       ied_src_ratio  ied_dst_ratio  device_role_entropy  \\\n",
              "count  121934.000000  121934.000000             121934.0   \n",
              "mean        0.495178       0.504822                  0.0   \n",
              "std         0.027205       0.027205                  0.0   \n",
              "min         0.000000       0.000000                  0.0   \n",
              "25%         0.500000       0.500000                  0.0   \n",
              "50%         0.500000       0.500000                  0.0   \n",
              "75%         0.500000       0.500000                  0.0   \n",
              "max         1.000000       1.000000                  0.0   \n",
              "\n",
              "       is_typical_scada_to_ied   src_ip_count   dst_ip_count  comm_pair_count  \\\n",
              "count            121934.000000  121934.000000  121934.000000    121934.000000   \n",
              "mean                  0.999615       3.187995       3.303820         4.492250   \n",
              "std                   0.019629       0.930113       0.928247         1.821498   \n",
              "min                   0.000000       1.000000       1.000000         1.000000   \n",
              "25%                   1.000000       2.000000       2.000000         2.000000   \n",
              "50%                   1.000000       4.000000       4.000000         6.000000   \n",
              "75%                   1.000000       4.000000       4.000000         6.000000   \n",
              "max                   1.000000       4.000000       4.000000         6.000000   \n",
              "\n",
              "       dominant_pair_ratio  multi_target_ratio  consecutive_write_max  \\\n",
              "count        121934.000000        121934.00000          121934.000000   \n",
              "mean              0.297255             0.18516               2.710097   \n",
              "std               0.154616             0.13683              92.511626   \n",
              "min               0.166667             0.00000               0.000000   \n",
              "25%               0.166667             0.00000               0.000000   \n",
              "50%               0.187500             0.25000               0.000000   \n",
              "75%               0.500000             0.25000               0.000000   \n",
              "max               1.000000             1.00000           12639.000000   \n",
              "\n",
              "       consecutive_write_mean  write_burst_count  read_write_alternation  \\\n",
              "count           121934.000000      121934.000000           121934.000000   \n",
              "mean                 1.321608           0.021741                0.003931   \n",
              "std                 75.384169           0.448722                0.016487   \n",
              "min                  0.000000           0.000000                0.000000   \n",
              "25%                  0.000000           0.000000                0.000000   \n",
              "50%                  0.000000           0.000000                0.000000   \n",
              "75%                  0.000000           0.000000                0.000000   \n",
              "max              12639.000000          22.000000                0.178571   \n",
              "\n",
              "       operation_sequence_entropy  write_without_read_ratio  \\\n",
              "count               121934.000000             121934.000000   \n",
              "mean                     0.022482                  0.000074   \n",
              "std                      0.087763                  0.008591   \n",
              "min                      0.000000                  0.000000   \n",
              "25%                      0.000000                  0.000000   \n",
              "50%                      0.000000                  0.000000   \n",
              "75%                      0.000000                  0.000000   \n",
              "max                      1.000000                  1.000000   \n",
              "\n",
              "       external_ip_present  external_ip_packet_ratio  unknown_ip_count  \\\n",
              "count        121934.000000             121934.000000          121934.0   \n",
              "mean              0.000385                  0.000385               0.0   \n",
              "std               0.019629                  0.019629               0.0   \n",
              "min               0.000000                  0.000000               0.0   \n",
              "25%               0.000000                  0.000000               0.0   \n",
              "50%               0.000000                  0.000000               0.0   \n",
              "75%               0.000000                  0.000000               0.0   \n",
              "max               1.000000                  1.000000               0.0   \n",
              "\n",
              "       abnormal_fc_ratio  address_range_exceeded  \n",
              "count           121934.0           121934.000000  \n",
              "mean                 0.0                0.000044  \n",
              "std                  0.0                0.001698  \n",
              "min                  0.0                0.000000  \n",
              "25%                  0.0                0.000000  \n",
              "50%                  0.0                0.000000  \n",
              "75%                  0.0                0.000000  \n",
              "max                  0.0                0.232558  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#   Feature statistical description\n",
        "print(\"Feature statistical description:\")\n",
        "df_features[feature_names].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "数据样例（前5行）:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fc_distribution_entropy</th>\n",
              "      <th>fc_diversity</th>\n",
              "      <th>fc_read_ratio</th>\n",
              "      <th>fc_write_ratio</th>\n",
              "      <th>txid_mean</th>\n",
              "      <th>txid_std</th>\n",
              "      <th>txid_unique_ratio</th>\n",
              "      <th>unit_id_diversity</th>\n",
              "      <th>packet_size_mean</th>\n",
              "      <th>packet_size_std</th>\n",
              "      <th>address_range</th>\n",
              "      <th>value_mean</th>\n",
              "      <th>value_std</th>\n",
              "      <th>packet_count</th>\n",
              "      <th>packet_rate</th>\n",
              "      <th>interval_mean</th>\n",
              "      <th>interval_std</th>\n",
              "      <th>interval_min</th>\n",
              "      <th>interval_max</th>\n",
              "      <th>burst_count</th>\n",
              "      <th>burst_intensity</th>\n",
              "      <th>session_count</th>\n",
              "      <th>scada_src_ratio</th>\n",
              "      <th>scada_dst_ratio</th>\n",
              "      <th>ied_src_ratio</th>\n",
              "      <th>ied_dst_ratio</th>\n",
              "      <th>device_role_entropy</th>\n",
              "      <th>is_typical_scada_to_ied</th>\n",
              "      <th>src_ip_count</th>\n",
              "      <th>dst_ip_count</th>\n",
              "      <th>comm_pair_count</th>\n",
              "      <th>dominant_pair_ratio</th>\n",
              "      <th>multi_target_ratio</th>\n",
              "      <th>consecutive_write_max</th>\n",
              "      <th>consecutive_write_mean</th>\n",
              "      <th>write_burst_count</th>\n",
              "      <th>read_write_alternation</th>\n",
              "      <th>operation_sequence_entropy</th>\n",
              "      <th>write_without_read_ratio</th>\n",
              "      <th>external_ip_present</th>\n",
              "      <th>external_ip_packet_ratio</th>\n",
              "      <th>unknown_ip_count</th>\n",
              "      <th>abnormal_fc_ratio</th>\n",
              "      <th>address_range_exceeded</th>\n",
              "      <th>scenario</th>\n",
              "      <th>pcap_file</th>\n",
              "      <th>window_start</th>\n",
              "      <th>window_end</th>\n",
              "      <th>packet_count_raw</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.907589</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16414.205882</td>\n",
              "      <td>271.537212</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>11.191176</td>\n",
              "      <td>0.878792</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68</td>\n",
              "      <td>4.533333</td>\n",
              "      <td>0.223642</td>\n",
              "      <td>0.981275</td>\n",
              "      <td>0.000371</td>\n",
              "      <td>4.755910</td>\n",
              "      <td>4</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0.191176</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>benign</td>\n",
              "      <td>network-wide-normal-14.pcap</td>\n",
              "      <td>2023-01-24 04:52:05.777466</td>\n",
              "      <td>2023-01-24 04:52:20.777466</td>\n",
              "      <td>68</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.911311</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16454.659091</td>\n",
              "      <td>282.421746</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>11.193182</td>\n",
              "      <td>0.877211</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88</td>\n",
              "      <td>5.866667</td>\n",
              "      <td>0.120688</td>\n",
              "      <td>0.711788</td>\n",
              "      <td>0.000414</td>\n",
              "      <td>4.760056</td>\n",
              "      <td>3</td>\n",
              "      <td>28.333333</td>\n",
              "      <td>6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0.170455</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>benign</td>\n",
              "      <td>network-wide-normal-14.pcap</td>\n",
              "      <td>2023-01-24 04:52:20.777466</td>\n",
              "      <td>2023-01-24 04:52:35.777466</td>\n",
              "      <td>88</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.921928</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16464.666667</td>\n",
              "      <td>281.222727</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>0.871780</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.118019</td>\n",
              "      <td>0.706653</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>4.777379</td>\n",
              "      <td>6</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>benign</td>\n",
              "      <td>network-wide-normal-14.pcap</td>\n",
              "      <td>2023-01-24 04:52:35.777466</td>\n",
              "      <td>2023-01-24 04:52:50.777466</td>\n",
              "      <td>90</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.921928</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16479.666667</td>\n",
              "      <td>281.222727</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>0.871780</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.118000</td>\n",
              "      <td>0.707162</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>4.781165</td>\n",
              "      <td>6</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>benign</td>\n",
              "      <td>network-wide-normal-14.pcap</td>\n",
              "      <td>2023-01-24 04:52:50.777466</td>\n",
              "      <td>2023-01-24 04:53:05.777466</td>\n",
              "      <td>90</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.921928</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16494.666667</td>\n",
              "      <td>281.222727</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>0.871780</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.117983</td>\n",
              "      <td>0.707165</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>4.780578</td>\n",
              "      <td>6</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>benign</td>\n",
              "      <td>network-wide-normal-14.pcap</td>\n",
              "      <td>2023-01-24 04:53:05.777466</td>\n",
              "      <td>2023-01-24 04:53:20.777466</td>\n",
              "      <td>90</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fc_distribution_entropy  fc_diversity  fc_read_ratio  fc_write_ratio  \\\n",
              "0                 1.907589             4            1.0             0.0   \n",
              "1                 1.911311             4            1.0             0.0   \n",
              "2                 1.921928             4            1.0             0.0   \n",
              "3                 1.921928             4            1.0             0.0   \n",
              "4                 1.921928             4            1.0             0.0   \n",
              "\n",
              "      txid_mean    txid_std  txid_unique_ratio  unit_id_diversity  \\\n",
              "0  16414.205882  271.537212                0.5                  1   \n",
              "1  16454.659091  282.421746                0.5                  1   \n",
              "2  16464.666667  281.222727                0.5                  1   \n",
              "3  16479.666667  281.222727                0.5                  1   \n",
              "4  16494.666667  281.222727                0.5                  1   \n",
              "\n",
              "   packet_size_mean  packet_size_std  address_range  value_mean  value_std  \\\n",
              "0         11.191176         0.878792           30.0         1.0        0.0   \n",
              "1         11.193182         0.877211           30.0         1.0        0.0   \n",
              "2         11.200000         0.871780           30.0         1.0        0.0   \n",
              "3         11.200000         0.871780           30.0         1.0        0.0   \n",
              "4         11.200000         0.871780           30.0         1.0        0.0   \n",
              "\n",
              "   packet_count  packet_rate  interval_mean  interval_std  interval_min  \\\n",
              "0            68     4.533333       0.223642      0.981275      0.000371   \n",
              "1            88     5.866667       0.120688      0.711788      0.000414   \n",
              "2            90     6.000000       0.118019      0.706653      0.000300   \n",
              "3            90     6.000000       0.118000      0.707162      0.000148   \n",
              "4            90     6.000000       0.117983      0.707165      0.000412   \n",
              "\n",
              "   interval_max  burst_count  burst_intensity  session_count  scada_src_ratio  \\\n",
              "0      4.755910            4        16.000000              6              0.5   \n",
              "1      4.760056            3        28.333333              6              0.5   \n",
              "2      4.777379            6        14.000000              6              0.5   \n",
              "3      4.781165            6        14.000000              6              0.5   \n",
              "4      4.780578            6        14.000000              6              0.5   \n",
              "\n",
              "   scada_dst_ratio  ied_src_ratio  ied_dst_ratio  device_role_entropy  \\\n",
              "0              0.5            0.5            0.5                  0.0   \n",
              "1              0.5            0.5            0.5                  0.0   \n",
              "2              0.5            0.5            0.5                  0.0   \n",
              "3              0.5            0.5            0.5                  0.0   \n",
              "4              0.5            0.5            0.5                  0.0   \n",
              "\n",
              "   is_typical_scada_to_ied  src_ip_count  dst_ip_count  comm_pair_count  \\\n",
              "0                      1.0             4             4                6   \n",
              "1                      1.0             4             4                6   \n",
              "2                      1.0             4             4                6   \n",
              "3                      1.0             4             4                6   \n",
              "4                      1.0             4             4                6   \n",
              "\n",
              "   dominant_pair_ratio  multi_target_ratio  consecutive_write_max  \\\n",
              "0             0.191176                0.25                      0   \n",
              "1             0.170455                0.25                      0   \n",
              "2             0.166667                0.25                      0   \n",
              "3             0.166667                0.25                      0   \n",
              "4             0.166667                0.25                      0   \n",
              "\n",
              "   consecutive_write_mean  write_burst_count  read_write_alternation  \\\n",
              "0                     0.0                  0                     0.0   \n",
              "1                     0.0                  0                     0.0   \n",
              "2                     0.0                  0                     0.0   \n",
              "3                     0.0                  0                     0.0   \n",
              "4                     0.0                  0                     0.0   \n",
              "\n",
              "   operation_sequence_entropy  write_without_read_ratio  external_ip_present  \\\n",
              "0                         0.0                       0.0                    0   \n",
              "1                         0.0                       0.0                    0   \n",
              "2                         0.0                       0.0                    0   \n",
              "3                         0.0                       0.0                    0   \n",
              "4                         0.0                       0.0                    0   \n",
              "\n",
              "   external_ip_packet_ratio  unknown_ip_count  abnormal_fc_ratio  \\\n",
              "0                       0.0                 0                0.0   \n",
              "1                       0.0                 0                0.0   \n",
              "2                       0.0                 0                0.0   \n",
              "3                       0.0                 0                0.0   \n",
              "4                       0.0                 0                0.0   \n",
              "\n",
              "   address_range_exceeded scenario                    pcap_file  \\\n",
              "0                     0.0   benign  network-wide-normal-14.pcap   \n",
              "1                     0.0   benign  network-wide-normal-14.pcap   \n",
              "2                     0.0   benign  network-wide-normal-14.pcap   \n",
              "3                     0.0   benign  network-wide-normal-14.pcap   \n",
              "4                     0.0   benign  network-wide-normal-14.pcap   \n",
              "\n",
              "                window_start                 window_end  packet_count_raw  \\\n",
              "0 2023-01-24 04:52:05.777466 2023-01-24 04:52:20.777466                68   \n",
              "1 2023-01-24 04:52:20.777466 2023-01-24 04:52:35.777466                88   \n",
              "2 2023-01-24 04:52:35.777466 2023-01-24 04:52:50.777466                90   \n",
              "3 2023-01-24 04:52:50.777466 2023-01-24 04:53:05.777466                90   \n",
              "4 2023-01-24 04:53:05.777466 2023-01-24 04:53:20.777466                90   \n",
              "\n",
              "    label  \n",
              "0  Normal  \n",
              "1  Normal  \n",
              "2  Normal  \n",
              "3  Normal  \n",
              "4  Normal  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#   Data sample\n",
        "print(\"Data sample (first 5 rows):\")\n",
        "df_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3.5 Step 3.5: Minimum Packet Count Filtering\n",
        "\n",
        "**Objective**: Filter windows with too few packets to ensure statistical feature validity\n",
        "\n",
        "**Rationale**: \n",
        "- Industrial control traffic is sparse, some windows have very few packets (<30 packets)\n",
        "- 30 is the classic threshold for \"large samples\" in statistics\n",
        "- With too few packets, statistical features like entropy and std dev are unstable\n",
        "\n",
        "**Threshold**: `packet_count >= 30`\n",
        "\n",
        "**Expected Result**: Retain about 60% of windows (~73,000 samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "已加载特征数据: 121,934 个窗口\n"
          ]
        }
      ],
      "source": [
        "#   Load saved feature data\n",
        "df_features = pd.read_parquet(str(OUTPUT_PATHS['features_15s']))\n",
        "print(f\"Feature data loaded: {len(df_features):,} windows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Step 3.5: 最小包数过滤\n",
            "============================================================\n",
            "\n",
            "过滤前窗口数: 121,934\n",
            "最小包数阈值: >= 30\n",
            "\n",
            "窗口包数分布:\n",
            "  最小: 1\n",
            "  最大: 12639\n",
            "  平均: 69.5\n",
            "  中位数: 80.0\n",
            "\n",
            "过滤结果:\n",
            "  过滤前: 121,934 个窗口\n",
            "  过滤后: 118,209 个窗口\n",
            "  移除: 3,725 个窗口\n",
            "  保留率: 96.9%\n"
          ]
        }
      ],
      "source": [
        "#   Minimum packet count threshold configuration\n",
        "MIN_PACKETS_THRESHOLD = 30\n",
        "\n",
        "#   Pre-filtering statistics\n",
        "print(\"=\" * 60)\n",
        "print(\"Step 3.5: Minimum Packet Count Filtering\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nWindows before filtering: {len(df_features):,}\")\n",
        "print(f\"Minimum packet threshold: >= {MIN_PACKETS_THRESHOLD}\")\n",
        "\n",
        "#   View packet count distribution\n",
        "print(f\"\\nWindow packet count distribution:\")\n",
        "print(f\"  Min: {df_features['packet_count'].min()}\")\n",
        "print(f\"  Max: {df_features['packet_count'].max()}\")\n",
        "print(f\"  Mean: {df_features['packet_count'].mean():.1f}\")\n",
        "print(f\"  Median: {df_features['packet_count'].median():.1f}\")\n",
        "\n",
        "#   Apply filtering\n",
        "df_features_filtered = df_features[df_features['packet_count'] >= MIN_PACKETS_THRESHOLD].copy()\n",
        "\n",
        "#   Post-filtering statistics\n",
        "filtered_count = len(df_features_filtered)\n",
        "original_count = len(df_features)\n",
        "removed_count = original_count - filtered_count\n",
        "retention_rate = filtered_count / original_count * 100\n",
        "\n",
        "print(f\"\\nFiltering results:\")\n",
        "print(f\"  Before: {original_count:,} windows\")\n",
        "print(f\"  After: {filtered_count:,} windows\")\n",
        "print(f\"  Removed: {removed_count:,} windows\")\n",
        "print(f\"  Retention rate: {retention_rate:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "按场景的过滤效果:\n",
            "------------------------------------------------------------\n",
            "  benign:\n",
            "    过滤前: 44,904 → 过滤后: 44,821 (保留 99.8%)\n",
            "    平均包数/窗口: 88.0\n",
            "  external:\n",
            "    过滤前: 47 → 过滤后: 7 (保留 14.9%)\n",
            "    平均包数/窗口: 1396.0\n",
            "  ied:\n",
            "    过滤前: 37,846 → 过滤后: 34,582 (保留 91.4%)\n",
            "    平均包数/窗口: 29.5\n",
            "  scada:\n",
            "    过滤前: 39,137 → 过滤后: 38,799 (保留 99.1%)\n",
            "    平均包数/窗口: 85.4\n"
          ]
        }
      ],
      "source": [
        "#   Analyze filtering effect by scenario\n",
        "print(\"\\nFiltering effect by scenario:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for scenario in df_features['scenario'].unique():\n",
        "    before = len(df_features[df_features['scenario'] == scenario])\n",
        "    after = len(df_features_filtered[df_features_filtered['scenario'] == scenario])\n",
        "    rate = after / before * 100 if before > 0 else 0\n",
        "    avg_pkt = df_features[df_features['scenario'] == scenario]['packet_count'].mean()\n",
        "    print(f\"  {scenario}:\")\n",
        "    print(f\"    Before: {before:,} → After: {after:,} (Retained {rate:.1f}%)\")\n",
        "    print(f\"    Avg packets/window: {avg_pkt:.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "过滤后标签分布:\n",
            "------------------------------------------------------------\n",
            "\n",
            "  过滤前:\n",
            "    Normal: 116,587 (95.6%)\n",
            "    Attack: 5,347 (4.4%)\n",
            "\n",
            "  过滤后:\n",
            "    Normal: 112,991 (95.6%)\n",
            "    Attack: 5,218 (4.4%)\n",
            "\n",
            "  Normal:Attack 比例 = 21.7:1\n"
          ]
        }
      ],
      "source": [
        "#   Post-filtering label distribution\n",
        "print(\"\\nLabel distribution after filtering:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "label_before = df_features['label'].value_counts()\n",
        "label_after = df_features_filtered['label'].value_counts()\n",
        "\n",
        "print(\"\\n  Before filtering:\")\n",
        "for label, count in label_before.items():\n",
        "    pct = count / len(df_features) * 100\n",
        "    print(f\"    {label}: {count:,} ({pct:.1f}%)\")\n",
        "\n",
        "print(\"\\n  After filtering:\")\n",
        "for label, count in label_after.items():\n",
        "    pct = count / len(df_features_filtered) * 100\n",
        "    print(f\"    {label}: {count:,} ({pct:.1f}%)\")\n",
        "\n",
        "#   Calculate class ratio\n",
        "if 'Attack' in label_after.index and 'Normal' in label_after.index:\n",
        "    ratio = label_after['Normal'] / label_after['Attack']\n",
        "    print(f\"\\n  Normal:Attack ratio = {ratio:.1f}:1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-09 16:37:29,235 - INFO - 数据已保存: c:\\Users\\Echo\\Desktop\\modbus-detection\\data\\processed\\features_15s_filtered.parquet\n",
            "2026-01-09 16:37:29,236 - INFO -   - 记录数: 118,209\n",
            "2026-01-09 16:37:29,237 - INFO -   - 文件大小: 7.31 MB\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ 过滤后特征数据已保存: c:\\Users\\Echo\\Desktop\\modbus-detection\\data\\processed\\features_15s_filtered.parquet\n",
            "✓ df_features 已更新为过滤后数据 (118,209 个窗口)\n"
          ]
        }
      ],
      "source": [
        "#   Save filtered feature data\n",
        "filtered_output_path = OUTPUT_PATHS['features_15s'].parent / 'features_15s_filtered.parquet'\n",
        "save_packets_to_parquet(df_features_filtered, str(filtered_output_path))\n",
        "print(f\"\\n✓ Filtered feature data saved: {filtered_output_path}\")\n",
        "\n",
        "#   Update df_features to filtered data (for Step 4)\n",
        "df_features = df_features_filtered\n",
        "print(f\"✓ df_features updated to filtered data ({len(df_features):,} windows)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Step 4: Dataset Split\n",
        "\n",
        "**Objective**: Split into Train/Validation/Test sets by PCAP files (70/15/15)\n",
        "\n",
        "**Principle**: Windows from the same file stay in the same set to prevent data leakage\n",
        "\n",
        "**Output**: `train.parquet`, `val.parquet`, `test.parquet`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "唯一PCAP文件数: 43\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "\n",
        "#   Get unique PCAP file list\n",
        "unique_files = df_features['pcap_file'].unique()\n",
        "print(f\"Unique PCAP files: {len(unique_files)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "文件级标签分布:\n",
            "file_label\n",
            "Attack    24\n",
            "Normal    19\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#   Determine primary label for each file (for stratified split)\n",
        "file_labels = df_features.groupby('pcap_file')['label'].apply(\n",
        "    lambda x: 'Attack' if 'Attack' in x.values else 'Normal'\n",
        ").reset_index()\n",
        "file_labels.columns = ['pcap_file', 'file_label']\n",
        "\n",
        "print(\"File-level label distribution:\")\n",
        "file_label_counts = file_labels['file_label'].value_counts()\n",
        "print(file_label_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "文件划分:\n",
            "  训练集: 29 个文件\n",
            "  验证集: 7 个文件\n",
            "  测试集: 7 个文件\n"
          ]
        }
      ],
      "source": [
        "#   Stratified split\n",
        "np.random.seed(PARAMS['random_seed'])\n",
        "\n",
        "#   First split out test set (15%)\n",
        "train_val_files, test_files = train_test_split(\n",
        "    file_labels['pcap_file'].values,\n",
        "    test_size=PARAMS['split_ratios']['test'],\n",
        "    stratify=file_labels['file_label'].values,\n",
        "    random_state=PARAMS['random_seed']\n",
        ")\n",
        "\n",
        "#   Then split validation set from remainder (15% of original = 15/85 of train_val)\n",
        "val_ratio_adjusted = PARAMS['split_ratios']['val'] / (1 - PARAMS['split_ratios']['test'])\n",
        "\n",
        "#   Get labels for train_val files\n",
        "train_val_labels = file_labels[file_labels['pcap_file'].isin(train_val_files)]['file_label'].values\n",
        "\n",
        "train_files, val_files = train_test_split(\n",
        "    train_val_files,\n",
        "    test_size=val_ratio_adjusted,\n",
        "    stratify=train_val_labels,\n",
        "    random_state=PARAMS['random_seed']\n",
        ")\n",
        "\n",
        "print(f\"File split:\")\n",
        "print(f\"  Train: {len(train_files)} files\")\n",
        "print(f\"  Validation: {len(val_files)} files\")\n",
        "print(f\"  Test: {len(test_files)} files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "窗口划分:\n",
            "  训练集: 83,078 个窗口 (70.3%)\n",
            "  验证集: 15,371 个窗口 (13.0%)\n",
            "  测试集: 19,760 个窗口 (16.7%)\n"
          ]
        }
      ],
      "source": [
        "#   Split data by files\n",
        "df_train = df_features[df_features['pcap_file'].isin(train_files)].copy()\n",
        "df_val = df_features[df_features['pcap_file'].isin(val_files)].copy()\n",
        "df_test = df_features[df_features['pcap_file'].isin(test_files)].copy()\n",
        "\n",
        "print(f\"\\nWindow split:\")\n",
        "print(f\"  Train: {len(df_train):,} windows ({len(df_train)/len(df_features)*100:.1f}%)\")\n",
        "print(f\"  Validation: {len(df_val):,} windows ({len(df_val)/len(df_features)*100:.1f}%)\")\n",
        "print(f\"  Test: {len(df_test):,} windows ({len(df_test)/len(df_features)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "各集合标签分布:\n",
            "  训练集: Normal=79732 (96.0%), Attack=3346 (4.0%)\n",
            "  验证集: Normal=14611 (95.1%), Attack=760 (4.9%)\n",
            "  测试集: Normal=18648 (94.4%), Attack=1112 (5.6%)\n"
          ]
        }
      ],
      "source": [
        "#   Check label distribution for each set\n",
        "print(\"Label distribution per set:\")\n",
        "for name, df in [('Train', df_train), ('Validation', df_val), ('Test', df_test)]:\n",
        "    label_dist = df['label'].value_counts()\n",
        "    normal = label_dist.get('Normal', 0)\n",
        "    attack = label_dist.get('Attack', 0)\n",
        "    total = len(df)\n",
        "    print(f\"  {name}: Normal={normal} ({normal/total*100:.1f}%), Attack={attack} ({attack/total*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ 训练/验证/测试集已保存\n"
          ]
        }
      ],
      "source": [
        "#   Save split datasets\n",
        "df_train.to_parquet(OUTPUT_PATHS['train'], index=False)\n",
        "df_val.to_parquet(OUTPUT_PATHS['val'], index=False)\n",
        "df_test.to_parquet(OUTPUT_PATHS['test'], index=False)\n",
        "\n",
        "print(\"✓ Train/validation/test sets saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ 划分元信息已保存\n"
          ]
        }
      ],
      "source": [
        "from feature_extractor import get_feature_names\n",
        "feature_names = get_feature_names()\n",
        "#   Save split metadata\n",
        "split_info = {\n",
        "    'created_at': datetime.now().isoformat(),\n",
        "    'params': PARAMS,\n",
        "    'total_windows': len(df_features),\n",
        "    'total_files': len(unique_files),\n",
        "    'train': {\n",
        "        'files': len(train_files),\n",
        "        'windows': len(df_train),\n",
        "        'normal': int(df_train['label'].value_counts().get('Normal', 0)),\n",
        "        'attack': int(df_train['label'].value_counts().get('Attack', 0))\n",
        "    },\n",
        "    'val': {\n",
        "        'files': len(val_files),\n",
        "        'windows': len(df_val),\n",
        "        'normal': int(df_val['label'].value_counts().get('Normal', 0)),\n",
        "        'attack': int(df_val['label'].value_counts().get('Attack', 0))\n",
        "    },\n",
        "    'test': {\n",
        "        'files': len(test_files),\n",
        "        'windows': len(df_test),\n",
        "        'normal': int(df_test['label'].value_counts().get('Normal', 0)),\n",
        "        'attack': int(df_test['label'].value_counts().get('Attack', 0))\n",
        "    },\n",
        "    'feature_count': len(feature_names),\n",
        "    'feature_names': feature_names\n",
        "}\n",
        "\n",
        "with open(OUTPUT_PATHS['split_info'], 'w', encoding='utf-8') as f:\n",
        "    json.dump(split_info, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"✓ Split metadata saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Summary and Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Phase 1: 数据准备 - 完成检查清单\n",
            "============================================================\n",
            "  ✗ packets_raw.parquet: N/A\n",
            "  ✓ packets_labeled.parquet: 103.38 MB\n",
            "  ✓ features_15s.parquet: 7.55 MB\n",
            "  ✓ train.parquet: 5.15 MB\n",
            "  ✓ val.parquet: 1.03 MB\n",
            "  ✓ test.parquet: 1.26 MB\n",
            "  ✓ split_info.json: 0.00 MB\n",
            "\n",
            "============================================================\n",
            "✗ 部分文件缺失，请检查\n"
          ]
        }
      ],
      "source": [
        "#   Phase 1 completion checklist\n",
        "print(\"=\" * 60)\n",
        "print(\"Phase 1: Data Preparation - Completion Checklist\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "checklist = [\n",
        "    ('packets_raw.parquet', OUTPUT_PATHS['packets_raw']),\n",
        "    ('packets_labeled.parquet', OUTPUT_PATHS['packets_labeled']),\n",
        "    ('features_15s.parquet', OUTPUT_PATHS['features_15s']),\n",
        "    ('train.parquet', OUTPUT_PATHS['train']),\n",
        "    ('val.parquet', OUTPUT_PATHS['val']),\n",
        "    ('test.parquet', OUTPUT_PATHS['test']),\n",
        "    ('split_info.json', OUTPUT_PATHS['split_info']),\n",
        "]\n",
        "\n",
        "all_exist = True\n",
        "for name, path in checklist:\n",
        "    exists = path.exists()\n",
        "    status = \"✓\" if exists else \"✗\"\n",
        "    size = f\"{path.stat().st_size / (1024*1024):.2f} MB\" if exists else \"N/A\"\n",
        "    print(f\"  {status} {name}: {size}\")\n",
        "    if not exists:\n",
        "        all_exist = False\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "if all_exist:\n",
        "    print(\"✓ Phase 1 data preparation complete!\")\n",
        "else:\n",
        "    print(\"✗ Some files missing, please check\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "数据集统计摘要:\n",
            "  总窗口数: 118,209\n",
            "  特征数: 44\n",
            "  样本/特征比: 2686.6:1\n",
            "\n",
            "标签分布:\n",
            "  Normal: 112,991 (95.6%)\n",
            "  Attack: 5,218 (4.4%)\n"
          ]
        }
      ],
      "source": [
        "#   Dataset statistics summary\n",
        "print(\"\\nDataset statistics summary:\")\n",
        "print(f\"  Total windows: {len(df_features):,}\")\n",
        "print(f\"  Features: {len(feature_names)}\")\n",
        "print(f\"  Sample/feature ratio: {len(df_features)/len(feature_names):.1f}:1\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "for label, count in df_features['label'].value_counts().items():\n",
        "    print(f\"  {label}: {count:,} ({count/len(df_features)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Phase 2 准备事项:\n",
            "============================================================\n",
            "\n",
            "1. 训练RF主模型\n",
            "   - 使用训练集训练Random Forest\n",
            "   - 在验证集上调优超参数\n",
            "   - 在测试集上评估最终性能\n",
            "\n",
            "2. 5-fold交叉验证\n",
            "   - 报告均值±标准差\n",
            "   - 确保结果稳定性\n",
            "\n",
            "3. 基础性能评估\n",
            "   - Accuracy, Precision, Recall, F1-Score\n",
            "   - 混淆矩阵\n",
            "   - AUC-ROC曲线\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#   Phase 2 preparation items\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Phase 2 Preparation:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\"\"\n",
        "1. Train RF main model\n",
        "   - Train Random Forest on training set\n",
        "   - Tune hyperparameters on validation set\n",
        "   - Evaluate final performance on test set\n",
        "\n",
        "2. 5-fold cross-validation\n",
        "   - Report mean ± std dev\n",
        "   - Ensure result stability\n",
        "\n",
        "3. Basic performance evaluation\n",
        "   - Accuracy, Precision, Recall, F1-Score\n",
        "   - Confusion matrix\n",
        "   - AUC-ROC curve\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "完成时间: 2026-01-09 16:18:56\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nCompletion time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "modbus-detection",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
